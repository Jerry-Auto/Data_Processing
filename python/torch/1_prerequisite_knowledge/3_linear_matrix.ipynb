{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a26a51a",
   "metadata": {},
   "source": [
    "介绍一些维度变换，线代矩阵运算的知识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38f662a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([0., 1., 2., 3.]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "B = A.clone()  # 通过分配新内存，将A的一个副本分配给B\n",
    "x = torch.arange(4, dtype=torch.float32)\n",
    "A, B,x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a65107",
   "metadata": {},
   "source": [
    "降维  \n",
    "计算其元素的和sum  \n",
    "mean或average  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99785218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4]), torch.Size([5, 4]), tensor(6.), tensor(190.))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,A.shape,x.sum(), A.sum()#降为标量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0c60b1",
   "metadata": {},
   "source": [
    "指定张量沿哪一个轴来通过求和降低一个维度，即指定的维度会被压成一维消失掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0c56e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([40., 45., 50., 55.]), torch.Size([4]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis0 = A.sum(axis=0)\n",
    "A_sum_axis0, A_sum_axis0.shape\n",
    "#轴0表示行，现在只有一行了，变成了行向量（1,4）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ff7cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6., 22., 38., 54., 70.]), torch.Size([5]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis1 = A.sum(axis=1)\n",
    "A_sum_axis1, A_sum_axis1.shape\n",
    "#轴1表示列，现在只有一列了，变成了列向量（5,1）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ad05c",
   "metadata": {},
   "source": [
    "非降维求和  \n",
    "广播机制要求维度相同，标量除外  \n",
    "keepdims保持维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "918fda20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 6.],\n",
       "         [22.],\n",
       "         [38.],\n",
       "         [54.],\n",
       "         [70.]]),\n",
       " torch.Size([5, 1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=1, keepdims=True)\n",
    "sum_A,sum_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a62323b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
       "        [0.1818, 0.2273, 0.2727, 0.3182],\n",
       "        [0.2105, 0.2368, 0.2632, 0.2895],\n",
       "        [0.2222, 0.2407, 0.2593, 0.2778],\n",
       "        [0.2286, 0.2429, 0.2571, 0.2714]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A / sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71aee52",
   "metadata": {},
   "source": [
    "线性代数矩阵运算  \n",
    "向量点积  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "456a3ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(4, dtype = torch.float32)\n",
    "x, y, torch.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09d026c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de4816e",
   "metadata": {},
   "source": [
    "矩阵与向量相乘  \n",
    "把矩阵看作一个列向量，列向量的每一行都是行向量  \n",
    "行向量与被乘的向量作点积  \n",
    "要求矩阵列数与向量size(也是行向量)相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51d74652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]),\n",
       " torch.Size([4]),\n",
       " tensor([ 14.,  38.,  62.,  86., 110.]),\n",
       " torch.Size([5]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, x.shape, torch.mv(A, x),torch.mv(A, x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a467a5",
   "metadata": {},
   "source": [
    "矩阵与矩阵的乘法  \n",
    "要求前面的列等于后面的行  \n",
    "可以把A看作列向量$\\begin{bmatrix} a1\\\\a2\\\\...\\\\am\\end{bmatrix}$，B看作行向量$\\begin{bmatrix} b1&b2&...&bn\\end{bmatrix}$  \n",
    "$C={\\left\\{a_i \\cdot b_j \\right\\}}_{m \\times n}$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3870e6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.,  6.,  6.],\n",
      "        [22., 22., 22.],\n",
      "        [38., 38., 38.],\n",
      "        [54., 54., 54.],\n",
      "        [70., 70., 70.]])\n",
      "torch.Size([5, 4]) torch.Size([4, 3]) torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "B = torch.ones(4, 3)\n",
    "C=torch.mm(A, B)\n",
    "print(C)\n",
    "print(A.shape,B.shape,C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ef2288",
   "metadata": {},
   "source": [
    "### 批量矩阵乘法\n",
    "假设第一个小批量数据包含$n$个矩阵$\\mathbf{X}_1,\\ldots, \\mathbf{X}_n$，\n",
    "形状为$a\\times b$，\n",
    "第二个小批量包含$n$个矩阵$\\mathbf{Y}_1, \\ldots, \\mathbf{Y}_n$，\n",
    "形状为$b\\times c$。  \n",
    "它们的批量矩阵乘法得到$n$个矩阵\n",
    "$\\mathbf{X}_1\\mathbf{Y}_1, \\ldots, \\mathbf{X}_n\\mathbf{Y}_n$，\n",
    "形状为$a\\times c$。  \n",
    "因此，[**假定两个张量的形状分别是$(n,a,b)$和$(n,b,c)$，\n",
    "它们的批量矩阵乘法输出的形状为$(n,a,c)$**]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88605630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 6])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((2, 1, 4))\n",
    "Y = torch.ones((2, 4, 6))\n",
    "torch.bmm(X, Y).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1256fd",
   "metadata": {},
   "source": [
    "向量范数计算  \n",
    "距离，二范数  \n",
    "L1范数，绝对值再求和  \n",
    "还有P范数，(sum(abs(xi)^p))^(1/p) 需要自己搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93e20c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4000720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(u).sum()#L1范数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b6b344",
   "metadata": {},
   "source": [
    "矩阵的Frobenius范数  \n",
    "矩阵元素平方和的平方根"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "340f3ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.ones((4, 9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e0f7b3",
   "metadata": {},
   "source": [
    "repeat_interleave 是 PyTorch 中用于按元素重复张量的方法，将 input 中的每个元素连续重复 repeats 次  \n",
    "torch.repeat_interleave(input, repeats, dim=None) → Tensor  \n",
    "    input：输入张量  \n",
    "    repeats：每个元素重复的次数（可以是整数或张量），连续重复  \n",
    "    dim：沿着哪个维度重复（如果为None，会先展平）  \n",
    "    \n",
    "A.repeat_interleave(repeats, dim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6c12d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat_interleave(x, 2): tensor([1, 1, 2, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "# repeat_interleave: 按元素连续重复\n",
    "result_interleave = torch.repeat_interleave(x, 2)\n",
    "print(\"repeat_interleave(x, 2):\", result_interleave)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e57ced6",
   "metadata": {},
   "source": [
    "按指定次数重复每个维度\n",
    "tensor.repeat(*sizes) → Tensor  \n",
    "*sizes：每个维度重复的次数（可以是一个整数元组或单独的参数）  \n",
    " 一维张量X_(m,)使用 repeat((n, h)) 时，PyTorch 会：  \n",
    " 1. 首先在 X 前面添加一个维度，变成 (1, m) , x_expanded = X.unsqueeze(0)\n",
    " 2. 然后应用 repeat((n, h)) , 形状: (n, m*h) , X_tile = x_expanded.repeat((n, h))  \n",
    "\n",
    "不是连续重复，整个维度重复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e5716d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.repeat(2): tensor([1, 2, 3, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# repeat: 按维度重复整个张量\n",
    "result_repeat = x.repeat(2)\n",
    "print(\"x.repeat(2):\", result_repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "468d38b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 1, 2, 3],\n",
      "        [1, 2, 3, 1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "result_repeat = x.repeat((2,2))\n",
    "print(result_repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f5eb9b",
   "metadata": {},
   "source": [
    "torch.max函数在指定维度上操作时，会返回一个包含两个张量的元组（namedtuple）：\n",
    "\n",
    "第一个张量是最大值本身。  \n",
    "第二个张量是这些最大值对应的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "204e15b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1543, -1.3496, -1.2837, -0.8476],\n",
       "         [-1.3621,  0.8969,  1.0386,  0.4951]]),\n",
       " tensor([-0.1543,  1.0386]),\n",
       " tensor([0, 2]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn((2, 4))\n",
    "(Y,index)=X.max(1)\n",
    "X,Y,index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
