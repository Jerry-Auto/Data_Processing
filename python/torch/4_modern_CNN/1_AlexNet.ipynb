{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6196c4ef",
   "metadata": {},
   "source": [
    "AlexNet  \n",
    "首次证明了学习到的特征可以超越手工设计的特征  \n",
    "AlexNet和LeNet的设计理念非常相似，但也存在显著差异。\n",
    "\n",
    "    AlexNet比相对较小的LeNet5要深得多。AlexNet由八层组成：五个卷积层、两个全连接隐藏层和一个全连接输出层。\n",
    "\n",
    "    AlexNet使用ReLU而不是sigmoid作为其激活函数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62724f7d",
   "metadata": {},
   "source": [
    "![alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a81d852",
   "metadata": {},
   "source": [
    "模型设计  \n",
    "在AlexNet的第一层，卷积窗口的形状是11*11。   \n",
    "由于ImageNet中大多数图像的宽和高比MNIST图像的多10倍以上，因此，需要一个更大的卷积窗口来捕获目标。   \n",
    "第二层中的卷积窗口形状被缩减为5\\*5，然后是 3\\*3。   \n",
    "此外，在第一层、第二层和第五层卷积层之后，加入窗口形状为3*3、步幅为2的最大汇聚层。   \n",
    "而且，AlexNet的卷积通道数目是LeNet的10倍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deeb9d3",
   "metadata": {},
   "source": [
    "在最后一个卷积层后有两个全连接层，分别有4096个输出。  \n",
    "这两个巨大的全连接层拥有将近1GB的模型参数。  \n",
    "由于早期GPU显存有限，原版的AlexNet采用了双数据流设计，使得每个GPU只负责存储和计算模型的一半参数。  \n",
    "幸运的是，现在GPU显存相对充裕，所以现在很少需要跨GPU分解模型（因此，本书的AlexNet模型在这方面与原始论文稍有不同）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386f90e1",
   "metadata": {},
   "source": [
    "激活函数  \n",
    "AlexNet将sigmoid激活函数改为更简单的ReLU激活函数。  \n",
    "一方面，ReLU激活函数的计算更简单，它不需要如sigmoid激活函数那般复杂的求幂运算。  \n",
    "另一方面，当使用不同的参数初始化方法时，ReLU激活函数使训练模型更加容易。  \n",
    "当sigmoid激活函数的输出非常接近于0或1时，这些区域的梯度几乎为0，因此反向传播无法继续更新一些模型参数。  \n",
    "相反，ReLU激活函数在正区间的梯度总是1。  \n",
    "因此，如果模型参数没有正确初始化，sigmoid函数可能在正区间内得到几乎为0的梯度，从而使模型无法得到有效的训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059677ff",
   "metadata": {},
   "source": [
    "容量控制和预处理  \n",
    "AlexNet通过暂退法（ 4.6节）控制全连接层的模型复杂度，而LeNet只使用了权重衰减。  \n",
    "为了进一步扩充数据，AlexNet在训练时增加了大量的图像增强数据，如翻转、裁切和变色。  \n",
    "这使得模型更健壮，更大的样本量有效地减少了过拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e0752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "net = nn.Sequential(\n",
    "    # 这里使用一个11*11的更大窗口来捕捉对象。\n",
    "    # 同时，步幅为4，以减少输出的高度和宽度。\n",
    "    # 另外，输出通道的数目远大于LeNet\n",
    "    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 使用三个连续的卷积层和较小的卷积窗口。\n",
    "    # 除了最后的卷积层，输出通道的数量进一步增加。\n",
    "    # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度\n",
    "    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nn.Flatten(),\n",
    "    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合\n",
    "    nn.Linear(6400, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(4096, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "    nn.Linear(4096, 10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
